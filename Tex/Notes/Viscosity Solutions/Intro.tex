\section{Introduction}

As previously mentioned, in many instances the value function arising from an optimal control problem may fail to be continuously 
differentiable. If that happens the derivation of the Hamilton-Jacobi equation is no longer valid, but more importantly 
the notion of classical solution to it does hold anymore. Therefore, we have to weaken the notion of solution in order to get 
a consistent and unique solution to the dynamic programming equation for non-differentiable value functions. The \textit{viscosity solution} 
is exactly what we are searching for. It arises from a standard procedure called vanishing viscosity, which allows us to compute the 
solution of a fully non-linear first order PDE as the limiting solution of quasilinear parabolic PDEs, obtained via infinitesimal 
perturbations of second order derivatives. 

\subsection{Non-differentiable value functions}

Let us consider the calculus of variation problem:

\begin{equation}
    \inf_{x\in Lip([0,1];[-1,1])} \int_t^{t_1} 1 + \frac{1}{4}(\dot{x}(s))^2 \,ds,
\end{equation}

where $Lip(I;U)$ is the collection of Lipschitz continuous functions from $I$ to $U$. The Hamiltonian related to 
this problem is:

\[H(t,x,p) = \max_{v\in [-1,1]} \left\{-v\cdot p - 1 - \frac{1}{4}v^2\right\}.\]

We can explicitly compute the Hamiltonian and get:

\[H(t,x,p)=p^2-1.\]

Then the Hamilton-Jacobi equations read:

\[\begin{cases}
    \dot{x}^{\ast}(s) = -H_p(s,x^{\ast}(s),p^{\ast}(s)) =  2p^{\ast}(s)\\
    \dot{p}^{\ast}(s) = H_x(s,x^{\ast}(s),p^{\ast}(s)) = 0,
\end{cases}\]

therefore, we get:

\[\dot{x}(s)^{\ast} = 2p^{\ast},\,s\in[0,1],\]

for some $p^{\ast}\in\R$. We now compute the exit time of $(s,x(s))=(s,2(s-t)p^{\ast}+x)$ with initial data $(t,x)$. If $p=0$ then:

\[\tau=1,\,\abs{x}<1.\]

If $p>0$ then $x(s)=2(s-t)p+x$ is increasing, which implies that the system is going to exit from the right boundary, that is from $x(s)=1$, and if 
that happens before time $s=1$ the exit time will be determined by:

\[2(s-t)p+x=1\Rightarrow s=t+\frac{1-x}{2p}.\]

$x(s)=1$ for $s<1$ if:

\[2(1-t)p+x\geq1\Rightarrow p\geq t+\frac{1-x}{2p},\]

therefore:

\[\tau=\begin{cases}
    1 & p\geq t+\frac{1-x}{2p} \\
    t+\frac{1-x}{2p} & p> t+\frac{1-x}{2p}.
\end{cases}\]

Analogously, if $p<0$:

\[\tau=\begin{cases}
    1 & p\leq t-\frac{1+x}{2p} \\
    t-\frac{1+x}{2p} & p< t-\frac{1+x}{2p}.
\end{cases}.\]

We now solve:

\[\inf_{p\in\R} \int_t^{\tau}1+p^2\,ds=\inf_{p\in\R}(1+p^2)(\tau-t)=\begin{cases}
    (1+p^2)(1-t), & p=0\text{ or }p>0\land p\geq \frac{1-x}{2(1-t)}\text{ or }p<0\land p\leq\frac{-1-x}{2(1-t)}\\
    (1+p^2)\frac{1-x}{2p}, & p>0\land p\geq \frac{1-x}{2(1-t)} \\
    -(1+p^2)\frac{1+x}{2p}, & p\leq\frac{-1-x}{2(1-t)},
\end{cases}\]

which is solved as follows:

\[V(t,x)=\begin{cases}
    1-t & \abs{x}\leq t \\
    1-t& \abs{x}\geq t,
\end{cases}\]

which is continuous on the whole space, but clearly no differentiable in $\abs{x}=t$.

\subsection{Vanishing viscosity}

We now euristichally expose a technique called vanishing viscosity, which is widely used in 
calculus of variations problems and will show us one of the origins of the viscosity 
solution notion. Let us consider the initial value problem:

\begin{equation}\label{4-1-fullynonlinear}
    \begin{cases}
        u_t + H(u,Du) = 0,& \R^n\times(0,+\infty) \\
        u = g,& \R^n\times\{t=0\}.
    \end{cases}
\end{equation}

The method of characteristics shows that there cannot be a smooth solution of the above problem over the whole positive 
real line. Indeed, a weaker notion of solution is needed. One approach is to use Hopf-Lax solution concept. We are not 
interested in it, instead we start by perturbing the system as:

\begin{equation}
    \begin{cases}
        u^{\epsilon}_t + H(u^{\epsilon},Du^{\epsilon}) -\epsilon\Delta u^{\epsilon}= 0,& \R^n\times(0,+\infty) \\
        u^{\epsilon} = g,& \R^n\times\{t=0\},
    \end{cases}
\end{equation}

so that the fully non-linear system in \ref{4-1-fullynonlinear} becomes a semilinear one, which turn out to have a smooth solution. 
Then, we take $\epsilon\to0$. We expect the solution $u^{\epsilon}$ to lose the bounds on the derivatives, as they strongly depend on the 
regularization effect of $\epsilon\Lambda$. Turns out that many times Ascoli-Arzela theorem's hypotheses are satisfied, that is $(u^{\epsilon})_{\epsilon}$ 
is uniformly bounded and equicontinuous, then we have local uniform convergence along a subsequence $u^{\epsilon_j}$. We now use the limit
$u\xleftarrow{j\to+\infty}u^{\epsilon_j}$ as a solution. 
We now it to be continuous but we lack information about its derivatives. We will then verify these information using test functions. 
Unlike the classical variational weak solution concept, where integration by part play the central role, we will use the maximum principle 
to translate the derivates of $u$ onto the test functions. 

Let us take $v\in C^{\infty}(\R^n\times(0,+\infty))$ and suppose that $u-v$ has a strict local maximum at $(x_0,t_0)$, then:

\[(u-v)(x_0,t_0) > (u-v)(x,t),\]

for all $(t,x)$ sufficiently close to $(x_0,t_0)$. It can be shown that it implies that there exists $J>0$ such that for all 
$j>J$ there exists $(x_{\epsilon_j},t_{\epsilon_j})$ such that:

\[(u^{\epsilon}-v)(x_{\epsilon_j},t_{\epsilon_j}) \geq (u^{\epsilon}-v)(x,t),\]

for $(x,t)$ sufficiently close to $(x_{\epsilon_j},t_{\epsilon_j})$ and such that:

\[(x_{\epsilon_j},t_{\epsilon_j})\xrightarrow{j\to+\infty}(x_0,t_0).\]

Because $(u^{\epsilon}-v)$ has a local maximum at $(x_{\epsilon_j},t_{\epsilon_j})$:

\[Du^{\epsilon_j}(x_{\epsilon_j},t_{\epsilon_j})=Dv(x_{\epsilon_j},t_{\epsilon_j}),\,u^{\epsilon_j}_t(x_{\epsilon_j},t_{\epsilon_j}) =v(x_{\epsilon_j},t_{\epsilon_j}),\]

and:

\[-\Lambda u^{\epsilon_j}(x_{\epsilon_j},t_{\epsilon_j}) \geq -\Lambda v(x_{\epsilon_j},t_{\epsilon_j}) \].

Therefore, we get:

\[v_t(x_{\epsilon_j},t_{\epsilon_j}) +H(Dv(x_{\epsilon_j},t_{\epsilon_j}) ,x_{\epsilon_j})\leq \Lambda v(x_{\epsilon_j},t_{\epsilon_j}) \xrightarrow{j\to+\infty}0\]

Analogous computations can be done for local minimum of $u-v$, obtaining the opposite inequality above.

We can now grasp the intuition behind the following definition.

\begin{definition}
    A viscosity solution of \ref{4-1-fullynonlinear} is a function $u$ bounded and uniformly continuous on $\R^n\times[0,T]$ for all $T>0$ such that 
    for all $v\in C^{+\infty}(\R^n\times(0,+\infty))$:

    \[v_t(x,t)+H(Dv(x,t),x)\leq0\]

    for all $(x,t)\in\arg \max\{u-v\}$ and:

    \[v_t(x,t)+H(Dv(x,t),x)\geq0\]

    for all $(x,t)\in\arg \min\{u-v\}$. Furthermore, $u\equiv g$ for $t=0$. 
\end{definition}

\subsection{Abstract dynamic programming}

We now present an abstraction of the dynamic programming principle, which will allow us to define the viscosity solutions of the dynamic programming 
equation. Let $\Sigma$ be a closed subset of a Banach space and $\mathcal{C}$ a collection of functions on $\Sigma$, closed under addition:

\[\phi,\psi\in\mathcal{C}\Rightarrow \phi+\psi\in\mathcal{C}.\]

We consider the family of operators $\{\mathcal{T}_{tr}\}_{t_0\leq t\leq r\leq t_1}$ such that: 

\begin{equation}\label{4-1-identityofT}
    \mathcal{T}_{tt}\phi = \phi,\, \forall\phi\in\mathcal{C},
\end{equation}

\begin{equation}\label{4-1-leqT}
    \mathcal{T}_{tr}\phi\leq\mathcal{T}_{ts}\psi \text{ if } \phi\leq \mathcal{T}_{rs}\psi,
\end{equation}

and:

\begin{equation}\label{4-1-geqT}
    \mathcal{T}_{tr}\phi\geq\mathcal{T}_{ts}\psi \text{ if } \phi\geq \mathcal{T}_{rs}\psi.
\end{equation}

Conditions \ref{4-1-leqT} and \ref{4-1-geqT} are a weaker version of monotonicity; they imply it together with \ref{4-1-identityofT}. 
Moreover, they also imply the semigroup property, provided that $\mathcal{T}_{rt}:\mathcal{C}\rightarrow\mathcal{C}$. Under this assumption,
the two conditions are equivalent to monotonicity. The semigroup property:

\begin{equation}
    \mathcal{T}_{tr}\left(\mathcal{T}_{rs}\psi\right)=\mathcal{T}_{ts}\psi,\,\mathcal{T}_{rs}\psi\in\mathcal{C},
\end{equation}

is going to be the dynamic programming principle. Indeed, let us consider the classical optimal control problem defined on a bounded set 
$O\subset\R^n$, which we set to be $\Sigma=\overline{O}$ and $\mathcal{C}=\mathcal{M}(\Sigma)$, the collection of measurable functions bounded by below. Then as in chapter 1 we aim at minimize a functional, 
we set this functional to be the operator $\mathcal{T}$. Let us define:

\begin{equation}\ref{4-1-valuefunctreform}
    \mathcal{T}_{t,r;u}\psi(x) = \int_t^{\tau\wedge r}L(s,x(s),u(s)),\,ds + g(\tau,x(\tau))\chi_{\tau<r} + \psi(x(r))\chi_{\tau\geq r}, 
\end{equation}

which gives:

\begin{equation}\ref{4-1-defofT_dynam}
    \mathcal{T}_{tr}\psi = \inf_{u\in\mathcal{U}(t,x)} \mathcal{T}_{t,r;u}\psi.
\end{equation}

Under the usual assumption on the running and terminal costs, as well as on the control space $U$ we now that the value function defined in ref{4-1-valuefunctreform} 
is measurable and bounded by below. Therefore, $\mathcal{T}_{rt}:\mathcal{C}\rightarrow\mathcal{C}$ and we can formulate the semigroup property just by asking $\psi\in\mathcal{C}$. 
It is clear by its definition that the dynamic programming principle is translated as:

\[\mathcal{T}_{tt_1}\psi(x)=\mathcal{T}_{tr}\left(\mathcal{T}_{rt_1}\psi\right)(x),\]

for $(t,x)\in\overline{Q}$ and $\psi\in\mathcal{C}$. We now derive the abstract dynamic programming equation. The same procedure as in chapter 1 gives:

\[-\frac{1}{h}\left[\mathcal{T}_{tt+h}V(t+h,\cdot)(x)-V(t,x)\right]=0.\]

What happens if we let $h\to0$? We ask for the existence of a family of non-linear operators which will play the role of the Hamiltonian. 
Let $\Sigma'\subset\Sigma$ and $\mathcal{D}\subset C([t_0,t_1)\times\Sigma')$ and $\{\mathcal{G}_t\}_{t\in[t_0,t_1]}$ functions on $\Sigma$ such that:

\begin{equation}
    \lim_{h\to 0}\frac{1}{h}\left[\mathcal{T}_{tt+h}V(t+h,\cdot)(x)-V(t,x)\right] = \frac{\partial}{\partial t}w(t,x) - (\mathcal{G}_tw(t,\cdot))(x)
\end{equation}

for all $w\in\mathcal{D},(t,x)\in Q$. 